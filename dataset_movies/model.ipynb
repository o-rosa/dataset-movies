{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import ndcg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "generos = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'ScienceFiction', 'TVMovie', 'Thriller', 'War', 'Western']\n",
    "\n",
    "def read_parquet(pasta):\n",
    "    arquivos_parquet = glob.glob(os.path.join(pasta, '*.parquet'))\n",
    "    lista_df = [pd.read_parquet(arquivo) for arquivo in arquivos_parquet]\n",
    "    df = pd.concat(lista_df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def normaliza_array(df, array_col):\n",
    "    matrix = np.vstack(df[array_col].values)\n",
    "    matrix_normalized = MinMaxScaler().fit_transform(matrix)\n",
    "    df[array_col] = list(matrix_normalized)\n",
    "    return df\n",
    "\n",
    "def array_to_column(df, array_col, prefixo):\n",
    "    nome_cols = [f'{prefixo}{g}' for g in generos]\n",
    "    \n",
    "    arrays_df = pd.DataFrame(df[array_col].tolist(), index=df.index, columns=nome_cols)\n",
    "    \n",
    "    return pd.concat([df.drop(array_col, axis=1), arrays_df], axis=1)\n",
    "\n",
    "def treino_teste(df, percent):\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    cutoff_index = int(len(df) * percent)\n",
    "    cutoff_timestamp = df.iloc[cutoff_index]['timestamp']\n",
    "    df_train = df[df['timestamp'] <= cutoff_timestamp]\n",
    "    df_test = df[df['timestamp'] > cutoff_timestamp]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = read_parquet('../output-train')\n",
    "df_parquet = df_parquet.sample(frac=1)\n",
    "df_parquet = array_to_column(df_parquet,'user_genero_avg', 'avg_')\n",
    "df_parquet = array_to_column(df_parquet,'generos_movie', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = treino_teste(df_parquet, 0.9)\n",
    "df_candidatos = read_parquet('../geracao_candidatos').sample(n=100, random_state=42)\n",
    "\n",
    "df_test = pd.merge(df_test, df_candidatos, on='imdbId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = normaliza_array(df_train,'user_genero_count')\n",
    "df_train = array_to_column(df_train,'user_genero_count', 'count_')\n",
    "df_test = normaliza_array(df_test,'user_genero_count')\n",
    "df_test = array_to_column(df_test,'user_genero_count', 'count_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feature = ['imdbId', 'timestamp', 'userId', 'movieId', 'rating', 'tmdbId']\n",
    "label = 'rating'\n",
    "generical_features = ['movie_popularity', 'movie_overall_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste com todas features\n",
    "\n",
    "X_train = df_train.drop(columns=no_feature)\n",
    "y_train = df_train[label]\n",
    "\n",
    "X_test = df_test.drop(columns=no_feature)\n",
    "y_test = df_test[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # só features especificas do usuario\n",
    "# X_train = X_train.drop(columns=generical_features)\n",
    "# X_test = X_test.drop(columns=generical_features)\n",
    "\n",
    "# # só features genericas\n",
    "# X_train = df_train[generical_features]\n",
    "# X_test = df_test[generical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.8203409440215338\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo de regressão\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação do modelo\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionar um usuário no teste com varios filmes e fazer o raking\n",
    "user_counts = (\n",
    "    df_test\n",
    "    .groupby('userId')\n",
    "    .size()\n",
    "    .reset_index(name='user_counts')\n",
    ")\n",
    "frequent_users = user_counts[user_counts['user_counts'] >= 7]['userId']\n",
    "df_filtered = df_test[df_test['userId'].isin(frequent_users)]\n",
    "\n",
    "\n",
    "df_user = df_filtered.iloc[[19]]\n",
    "user_id = df_user['userId'].tolist()[0]\n",
    "df_movies_user = df_test[df_test['userId'] == user_id]\n",
    "Y_user = df_movies_user[label]\n",
    "X_user = df_movies_user.drop(columns=no_feature)\n",
    "user_predictions = model.predict(X_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movieId  predicted_rating Y_user\n",
      "314     858          4.523031    4.0\n",
      "316    2324          4.268040    5.0\n",
      "313    1258          4.210135    5.0\n",
      "317    1270          3.912211    5.0\n",
      "302     260          3.797797    3.0\n",
      "373    1527          3.736726    3.0\n",
      "334    3996          3.725981    5.0\n",
      "315    2078          3.608398    5.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_predictions_df = pd.DataFrame({\n",
    "    'movieId': df_movies_user['movieId'],\n",
    "    'predicted_rating': user_predictions,\n",
    "    'Y_user': Y_user\n",
    "})\n",
    "\n",
    "# Gerando o ranking dos filmes com base nas previsões\n",
    "user_ranking = user_predictions_df.sort_values(by='predicted_rating', ascending=False)\n",
    "print(user_ranking.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.9540\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_ratings = np.array([user_predictions_df['Y_user'].values])\n",
    "predicted_ratings = np.array([user_predictions_df['predicted_rating'].values])\n",
    "ndcg = ndcg_score(true_ratings, predicted_ratings)\n",
    "\n",
    "print(f\"NDCG: {ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
